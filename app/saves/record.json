{"notes":[{"title":"gtor","lastOpen":1559908791521,"TotalTime":106390565,"words":0,"path":"D:\\Projects\\XNote\\app\\saves\\gtor.md","content":"\r\n# A General Theory of Reactivity\r\n\r\n*A work in progress.*\r\n\r\nIn the context of a computer program, reactivity is the process of receiving\r\nexternal stimuli and propagating events.\r\nThis is a rather broad definition that covers a wide variety of topics.\r\nThe term is usually reserved for systems that respond in turns to sensors,\r\nschedules, and above all, problems that exist between the chair and keyboard.\r\n\r\nThe field of reactivity is carved into plots ranging from \"reactive programming\"\r\nto the subtly distinct \"*functional* reactive programming\", with acrage set\r\naside for \"self adjusting computation\" and with neighbors like \"bindings\" and\r\n\"operational transforms\".\r\nAdherents favor everything from \"continuation passing style\" to \"promises\", or\r\nthe related concepts of \"deferreds\" and \"futures\".\r\nOther problems lend themselves to \"observables\", \"signals\", or \"behaviors\", and\r\neveryone agrees that \"streams\" are a good idea, but \"publishers\" and\r\n\"subscribers\" are distinct.\r\n\r\nIn 1905, Einstein created a theory of special relativity that unified the\r\nconcepts of space and time, and went on to incorporate gravity, to bring the\r\nthree fundamentals of physical law into a single model.\r\nTo a similar end, [various][Rx] minds in the field of reactivity have been\r\nconverging on a model that unifies at least promises and observables.\r\n\r\n[Rx]: https://github.com/Reactive-Extensions/RxJS/blob/aaebfe8962cfa06a6c80908d079928ba5b800c66/doc/readme.md\r\n\r\n             | **Singular**         | **Plural**\r\n:----------: | :------------------: | :---------------------:\r\n**Spatial**  | Value                | Iterable&lt;Value&gt;\r\n**Temporal** | Promise&lt;Value&gt; | Observable&lt;Value&gt;\r\n\r\nHowever, this description fails to capture all of the varigated concepts of\r\nreactivity.\r\nRather, Rx conflates all reactive primitives into a single Observable type that\r\ncan perform any role.\r\nJust as an array is an exemplar of an entire taxonomy of collections, promises,\r\nstreams, and observables are merely representatives of their class of reactive\r\nprimitives.\r\nAs the common paraphrase of Einstein goes, everything should be made as simple\r\nas possible, but no simpler.\r\n\r\n\r\n## Concepts\r\n\r\nFor the purpose of discussion, we must establish a vocabulary.\r\nSome of these names have a long tradition, or at least some precedent in\r\nJavaScript.\r\nSome are disputed, borrowed, or fabricated.\r\n\r\nA **value** is **singular** and **spatial**.\r\nIt can be accessed or modified.\r\nIf we break this atom, it will fall into two parts: the **getter** and the\r\n**setter**.\r\nData flows in one direction, from the setter to the getter.\r\n\r\nThe duality of a getter and a setter, a producer and a consumer, or a writer and\r\na reader, exists in every reactive primitive.\r\nErik Meijer shows us the parallelism and reflection that exists between various\r\ntypes of reactive duals in his [keynote for Lang.NEXT, 2014][EM].\r\n\r\n[EM]: http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Keynote-Duality\r\n\r\nSingular is as opposed to **plural** or multiple.\r\nAn array, or generally any collection, contains multiple values.\r\nAn **iterator** is a plural getter.\r\nA **generator** and iterator form the plural dual for values in space.\r\n\r\nSpatial is as opposed to **temporal**.\r\nReactivity is about time.\r\n\r\nA **promise** is a getter for a single value from the past or the future.\r\nIn JavaScript, and in the language E from which we borrowed the concept, the\r\ncorresponding setter is a **resolver**.\r\nCollectively, an asynchronous value is a **deferred**.\r\n\r\nIf a promise is the temporal analogue of a value, a **stream** is the temporal\r\nanalogue of an array.\r\nThe producer side of a stream is a writer and the consumer side is a reader.\r\nA **reader** is an asynchronous iterator and a **writer** is an asynchronous\r\ngenerator.\r\n\r\n\r\nInterface  |               |          |          |\r\n---------- | ------------- | -------- | -------- |\r\nValue      | Value         | Singular | Spatial  |\r\nGetter     | Getter        | Singular | Spatial  |\r\nSetter     | Setter        | Singular | Spatial  |\r\nArray      | Value         | Plural   | Spatial  |\r\nIterator   | Getter        | Plural   | Spatial  |\r\nGenerator  | Setter        | Plural   | Spatial  |\r\nDeferred   | Value         | Singular | Temporal |\r\nPromise    | Getter        | Singular | Temporal |\r\nResolver   | Setter        | Singular | Temporal |\r\nStream     | Value         | Plural   | Temporal |\r\nReader     | Getter        | Plural   | Temporal |\r\nWriter     | Setter        | Plural   | Temporal |\r\n\r\n\r\n### Singular and temporal\r\n\r\nAn observer can subscribe to eventually see the value of a promise.\r\nThey can do this before or after the promise has a value.\r\nAny number of observers can subscribe multiple times and any single observer can\r\nsubscribe to the same promise multiple times.\r\n\r\nAs such, promises model dependency.\r\nPromises and resolvers can be safely distributed to any number of producers and\r\nconsumers.\r\nIf multiple producers race to resolve a promise, the experience of each producer\r\nis indistinguishable regardless of whether they won or lost the race.\r\nLikewise, if multiple consumers subscribe to a promise, the experience of each\r\nconsumer is indistinguishable.\r\nOne consumer cannot prevent another consumer from making progress.\r\nInformation flows in one direction.\r\nPromises make reactive programs more robust and composable.\r\n\r\nPromises are **broadcast**.\r\n\r\nThe law that no consumer can interfere with another consumer makes it impossible\r\nfor promises to abort work in progress.\r\nA promise represents a result, not the work leading to that result.\r\n\r\nA **task** has mostly the same form and features as a promise, but is unicast by\r\ndefault and can be cancelled.\r\nA task can have only one subscriber, but can be explicitly forked to create a\r\nnew task that depends on the same result.\r\nEach subscriber can unsubscribe, and if all subscribers have unsubscribed and no\r\nfurther subscribers can be introduced, a task can abort its work.\r\n\r\nTasks are **unicast** and therefore cancelable.\r\n\r\nSee the accompanying sketch of a [task][] implementation.\r\n\r\n[task]: http://kriskowal.github.io/gtor/docs/task\r\n\r\nThere is also an esoteric difference between a promise and a future.\r\nPromise resolvers accept either a value or a promise and will recursively unwrap\r\ntransitive promises for promises.\r\nIn most if not all strongly typed languages, this behavior makes it hard if not\r\nimpossible to infer the type of a promise.\r\nA **future** is a promise’s strongly typed alter ego, which can take advantage\r\nof type inference to avoid having to explicitly cast the type of a promise.\r\n\r\nPromises, tasks, and futures are three variations of a singular reactive value.\r\nThey vary by being either broadcast or unicast, or by being suitable for strong\r\nor weak type systems.\r\n\r\n\r\n### Plural and temporal\r\n\r\nThere are many plural reactive value types.\r\nEach has a different adaptation for dealing with limited resources.\r\n\r\nA **stream** has many of the same constraints as an array.\r\nImagine a plane with space and time.\r\nIf you rotate an array from the space axis to the time axis, it would become a\r\nstream.\r\nThe order is important, and every value is significant.\r\n\r\nConsumers and producers are unlikely to process values at the same rate.\r\nIf the consumer is faster than the producer, it must idle between receiving\r\nvalues.\r\nIf a producer is faster than their corresponding consumer, it must idle between\r\nsending values.\r\n\r\nThis pushing and pulling is captured by the concept of **pressure**.\r\nOn the producer side, a vacuum stalls the consumer and a pressure sends values\r\nforward.\r\nOn the consumer side, a vacuum draws values forward and pressure, often called\r\n**back pressure**, stalls the producer.\r\nPressure exists to ensure that every value transits the setter to the getter.\r\n\r\nSince the consumer of a stream expects to see every value, streams are **unicast**\r\nlike tasks.\r\nAs they are unicast they are also cancelable.\r\nStreams are a cooperation between the reader and the writer and information\r\nflows both ways.\r\nData flows forward, acknowledgements flow backward, and either the consumer or\r\nproducer can terminate the flow.\r\n\r\nAlthough a stream is unicast, it is certainly possible to branch a stream into\r\nmultiple streams in a variety of ways.\r\nA fork in a stream is an operator that ensures that every value gets sent to\r\neach of an array of consumers.\r\nThe slowest of the forks determines the pressure, so the pressure of a fork can\r\nonly be higher than that of a single consumer.\r\nThe simpler strategy of providing a stream to multiple consumers produces a\r\n“round robin” load balancing effect, where each consumer receives an exclusive,\r\npossibly random, portion of the stream.\r\nThe pressure of a shared stream can only be lower than that of a single\r\nconsumer.\r\n\r\nIn the following example, the `map` operator creates two new streams from a\r\nsingle input stream.\r\nThe slow map will see half as many values as the fast map.\r\nThe slow map will consume and produce five values per second, and the fast map\r\nwill consume and produce ten, sustaining a maximum throughput of fifteen values\r\nper second if the original stream can produce values that quickly.\r\nIf the original stream can only produce ten or less values per second, the\r\nvalues will be distributed fairly between both consumers.\r\n\r\n```js\r\nvar slow = stream.map(function (n) {\r\n    return Promise.return(n).delay(200);\r\n});\r\nvar fast = stream.map(function (n) {\r\n    return Promise.return(n).delay(100);\r\n});\r\n```\r\n\r\nIn contrast, **publishers** and **subscribers** are **broadcast**.\r\nInformation flows only one direction, from the publishers to the subscribers.\r\nAlso, there is no guarantee of continuity.\r\nThe publisher does not wait for a subscriber and the subscriber receives\r\nwhatever values were published during the period of their subscription.\r\nA stream would buffer all values produced until the consumer arrives.\r\n\r\nWith *time series data*, values that change over time but belie\r\nthe same meaning, order and integrity may not be important.\r\nFor example, if you were bombarded with weather forecasts, you could discard\r\nevery report except the one you most recently received.\r\nAlternately, consider a value that represents the current time.\r\nSince the current time is always changing, it would not be meaningful, much less\r\npossible, to respond every moment it changes.\r\n\r\nTime series data comes in two varieties: **discrete** and **continuous**.\r\nDiscrete values should be **pushed** whereas continuous values should be\r\n**pulled** or **polled**.\r\n(If a homophone is a disaster, what are synonymous homophones?)\r\n\r\nThe current time or temperature are examples of **continuous behaviors**.\r\nAnimation frames and morse code are examples of **discrete signals**.\r\n\r\n\r\n## Primitives\r\n\r\nLet us consider each primitive in detail.\r\nSince the temporal primitives have spatial analogies, and since some of these\r\nspatial primitives are relatively new to JavaScript, we will review these first.\r\n\r\n\r\n### Iterators\r\n\r\nAn iterator is an object that allows us to lazily but synchronously consume\r\nmultiple values.\r\nIterators are not new to JavaScript, but there is a new standard forming at time\r\nof writing.\r\n\r\nIterators implement a `next()` method that returns an object that may have a\r\n`value` property, and may have a `done` property.\r\nAlthough the standard does not give this object a name, we will call it an\r\n**iteration**.\r\nIf the iterator has produced the entirety of a sequence, the `done` property of\r\nthe iteration will be `true`.\r\nGenerator functions return iterators that expand on this basic definition.\r\nThe `value` of a non-final iteration corresponds to a `yield` expression and the\r\n`value` of a `done` iteration corresponds to a `return` expression.\r\n\r\nIterators are an interface with many implementations.\r\nThe canonical iterator yields the values from an array.\r\n\r\n```js\r\nvar iterator = iterate([1, 2, 3]);\r\nvar iteration = iterator.next();\r\nexpect(iteration.value).toBe(1);\r\niteration = iterator.next();\r\nexpect(iteration.value).toBe(2);\r\niteration = iterator.next();\r\nexpect(iteration.value).toBe(3);\r\niteration = iterator.next();\r\nexpect(iteration.done).toBe(true);\r\n```\r\n\r\nWhat distinguishes an iterator from an array is that it is **lazy**.\r\nAn iterator does not necessarily end.\r\nWe can have iterators for non-terminating sequences, like counting or the\r\nfibonacci sequence.\r\nThe `range` function produces a sequence of values within an interval and\r\nseparated by a stride.\r\n\r\n```js\r\nfunction range(start, stop, step) {\r\n    return {next: function () {\r\n        var iteration;\r\n        if (start < stop) {\r\n            iteration = {value: start};\r\n            start += step;\r\n        } else {\r\n            iteration = {done: true};\r\n        }\r\n        return iteration;\r\n    }};\r\n}\r\n```\r\n\r\nIf the `stop` value of the range is `Infinity`, the iterator will have no end,\r\nand will never produce a `done` iteration.\r\nUnlike an array, an indefinite iterator consumes no more memory than an empty\r\none.\r\n\r\n```js\r\nvar iterator = range(0, Infinity, 1);\r\nexpect(iterator.next().value).toBe(0);\r\nexpect(iterator.next().value).toBe(1);\r\nexpect(iterator.next().value).toBe(2);\r\n// ...\r\n```\r\n\r\nThe **eager** equivalent would produce an array, but would only work for bounded\r\nintervals since it must create an exhaustive collection in memory before\r\nreturning.\r\n\r\n```js\r\nfunction range(start, stop, step) {\r\n    var result = [];\r\n    while (start < stop) {\r\n        result.push(start);\r\n        start += step;\r\n    }\r\n    return result;\r\n}\r\n\r\nexpect(range(0, 6, 2)).toEqual([0, 2, 4]);\r\n```\r\n\r\nIterators may have alternate implementations of some methods familiar from\r\narrays.\r\nFor example, `forEach` would walk the iterator until it is exhausted.\r\n`map` would produce a new iterator of values passed through some transform,\r\nwhile `filter` would produce a new iterator of the values that pass a test.\r\nAn iterator can support `reduce`, which would exhaust the iteration, but\r\n`reduceRight` would be less sensible since iterators only walk forward.\r\nIterators may also have some methods that are unique to their character, like\r\n`dropWhile` and `takeWhile`.\r\n\r\nWe can save time and space by implementing pipelines with iterators instead of\r\narrays.\r\nThe following example can be interpreted as either eager or lazy, depending on\r\nwhether `range` returns an array or an iterator.\r\nIf we start with an array, `map` will create another array of 1000 values and\r\n`filter` will create another large array.\r\nIf we start with an iterator, we will never construct an array of any size,\r\ninstead percolating one value at a time as the reducer pulls them from the\r\nfilter, as the filter pulls them from the mapping, and as the mapping pulls them\r\nfrom the range.\r\n\r\n```js\r\nrange(0, 1000, 1)\r\n.map(function (n) {\r\n    return n * 2;\r\n})\r\n.filter(function (n) {\r\n    return n % 3 !== 0;\r\n})\r\n.reduce(function (a, b) {\r\n    return a + b;\r\n})\r\n```\r\n\r\n\r\n### Generator Functions\r\n\r\nConsider the eager and lazy `range` function implementations.\r\nWe lose a certain clarity when we convert the array range maker into an iterator\r\nrange maker.\r\nGenerator functions alleviate this problem by offering a way to express\r\niterations procedurally, with a lazy behavior.\r\n\r\nA JavaScript engine near you may already support generator functions.\r\nThe syntax consists of adding an asterisk to the function declaration and using\r\n`yield` to produce iterations.\r\nCalling a generator function does not execute the function, but instead sets up\r\na state machine to track where we are in the function and returns an iterator.\r\nWhenever we ask the iterator for an iteration, the state machine will resume the\r\nexecution of the function until it produces an iteration or terminates.\r\n\r\n```js\r\nfunction *range(start, stop, step) {\r\n    while (start < stop) {\r\n        yield start;\r\n        start += step;\r\n    }\r\n}\r\n\r\nvar iterator = range(0, Infinity, 1);\r\nexpect(iterator.next().value).toBe(0);\r\nexpect(iterator.next().value).toBe(1);\r\nexpect(iterator.next().value).toBe(2);\r\n// ...\r\n```\r\n\r\nNotice that the range generator function restores and perhaps even exceeds the\r\nclarity of the range array maker.\r\n\r\nCalling `next` has three possible outcomes.\r\nIf the iterator encounters a `yield`, the iteration will have a `value`.\r\nIf the iterator runs the function to either an express or implied `return`, the\r\niteration will have a `value` and `done` will be true.\r\nIf the iterator runs to an explicit return, this terminal iteration carries the\r\nreturn value.\r\nIf the generator function throws an error, this will propagate out of `next()`.\r\n\r\nGenerators and iterators are **unicast**.\r\nThe consumer expects to see every value from the producer.\r\nSince generators and iterators cooperate, information flows both forward as\r\nvalues, and backward as requests for more values.\r\n\r\nHowever, the consumer can send other information back to the producer.\r\nThe `next` method, familiar from basic iterators, gains the ability to determine\r\nthe value of the `yield` expression from which the generator resumes.\r\nAs a trivial example, consider a generator that echoes whatever the consumer\r\nrequests.\r\n\r\n```js\r\nfunction *echo() {\r\n    var message;\r\n    while (true) {\r\n        message = yield message;\r\n    }\r\n}\r\n\r\nvar iterator = echo();\r\nexpect(iterator.next().value).toBe(undefined);\r\nexpect(iterator.next(\"Hello\").value).toBe(undefined);\r\nexpect(iterator.next(\"Goodbye\").value).toBe(\"Hello\");\r\nexpect(iterator.next().value).toBe(\"Goodbye\");\r\nexpect(iterator.next().value).toBe(undefined);\r\n```\r\n\r\nWe must prime the generator because it does not begin with a `yield`.\r\nWe advance the state machine to the first `yield` and allow it to produce the\r\ninitial, undefined message.\r\nWe then populate the message variable with a value, receiving its former\r\nundefined content again.\r\nThen we begin to see the fruit of our labor as the values we previously sent\r\nbackward come forward again.\r\nThis foreshadows the ability of stream readers to push back on stream writers.\r\n\r\nAdditionally, the iterator gains a `throw` method that allows the iterator to\r\nterminate the generator by causing the `yield` expression to raise the given\r\nerror.\r\nThe error will unravel the stack inside the generator.\r\nIf the error unravels a try-catch-finally block, the catch block may handle the\r\nerror, leaving the generator in a resumable state if the returned iteration is\r\nnot `done`.\r\nIf the error unravels all the way out of the generator, it will pass into the\r\nstack of the `throw` caller.\r\n\r\nThe iterator also gains a `return` method that causes the generator to resume as\r\nif from a `return` statement, regardless of whether it actually paused at a\r\n`yield` expression.\r\nLike a thrown error, this unravels the stack, executing finally blocks, but not\r\ncatch blocks.\r\n\r\nAs such, like `next`, the `throw` and `return` methods may either return an\r\niteration, done or not, or throw an error.\r\nThis foreshadows the ability of a stream reader to prematurely stop a stream\r\nwriter.\r\n\r\n```js\r\niterator.throw(new Error(\"Do not want!\"));\r\n```\r\n\r\nNote that in Java, [iterators][Java Iterator] have a `hasNext()` method.\r\nThis is not implementable for generators owing to the [Halting Problem][].\r\nThe iterator must try to get a value from the generator before the generator can\r\nconclude that it cannot produce another value.\r\n\r\n[Java Iterator]: http://docs.oracle.com/javase/7/docs/api/java/util/Iterator.html\r\n[Halting Problem]: http://en.wikipedia.org/wiki/Halting_problem\r\n\r\n\r\n### Generators\r\n\r\nThere is no proposal for a standard generator, but for the sake of completeness,\r\nif an array iterator consumes an array, an array generator would lazily produce\r\none.\r\nAn array generator object would implement `yield` as a method with behavior\r\nanalogous to the same keyword within a generator function.\r\nThe `yield` method would add a value to the array.\r\n\r\n```js\r\nvar array = [];\r\nvar generator = generate(array);\r\ngenerator.yield(10);\r\ngenerator.yield(20);\r\ngenerator.yield(30);\r\nexpect(array).toEqual([10, 20, 30]);\r\n```\r\n\r\n\r\nSince ECMAScript 5, at Doug Crockford’s behest, JavaScript allows keywords to be\r\nused for property names, making this parallel between keywords and methods\r\npossible.\r\nA generator might also implement `return` and `throw` methods, but a meaningful\r\nimplementation for an array generator is a stretch of the imagination.\r\nAlthough an array generator is of dubious utility, it foreshadows the interface\r\nof asynchronous generators, for which meaningful implementations of `return` and\r\n`throw` methods are easier to obtain, and go on to inform a sensible design for\r\nasynchronous generator functions.\r\n\r\n\r\n### Asynchronous Values\r\n\r\nThe asynchronous analogue of a getter is a promise.\r\nEach promise has a corresponding resolver as its asynchronous setter.\r\nCollectively the promise and resolver are a deferred value.\r\n\r\nThe salient method of a promise is `then`, which creates a new promise for the\r\nresult of a function that will eventually observe the value of the promise.\r\nIf a promise were plural, the `then` method might be called `map`.\r\nIf you care to beg an esoteric distinction, it might be called `map` if the\r\nobserver returns a value and `flatMap` if the observer returns a promise.\r\nThe `then` method of a promise allows either.\r\n\r\n```js\r\nvar promiseForThirty = promiseForTen.then(function (ten) {\r\n    return ten + 20;\r\n})\r\n```\r\n\r\nPromises can also have a `done` method that observes the value but does not\r\nreturn a promise nor captures the result of the observer.\r\nAgain, if a promise were plural, the `done` method might be called `forEach`.\r\n\r\n```js\r\npromiseForTen.done(function (ten) {\r\n});\r\n```\r\n\r\nThe `then` method also supports a second function that would observe whether the\r\ninput promise radiates an exception, and there is a `catch` method to use as a\r\nshorthand if you are only interested in catching errors.\r\n\r\n```js\r\npromise.then(onreturn, onthrow);\r\npromise.catch(onthrow);\r\n```\r\n\r\nAt this point, the design described here begins to differ from the standard\r\n`Promise` proposed for ECMAScript 6, arriving in browsers at time of writing.\r\nThe purpose of these differences is not to propose an alternative syntax, but to\r\nreinforce the relationship between a promise and its conceptual neighbors.\r\n\r\nA resolver is the singular analogue of a generator.\r\nRather than yielding, returning, and throwing errors, the resolver can only\r\nreturn or throw.\r\n\r\n```js\r\nresolver.return(10);\r\nresolver.throw(new Error(\"Sorry, please return during business hours.\"));\r\n```\r\n\r\nWith the standard promise, a free `resolve` function is sufficient and ergonomic\r\nfor expressing both of these methods.\r\n`resolver.return(promise)` is equivalent to `resolve(promise)`.\r\n`resolver.return(10)` is equivalent to `resolve(10)` or\r\n`resolve(Promise.resolve(10))`since non-promise values are automatically boxed\r\nin an already-fulfilled promise.\r\n`resolver.throw(error)` is equivalent to `resolve(Promise.reject(error))`.\r\nIn all positions, `resolve` is the temporal analogue of `return` and `reject` is\r\nthe temporal analogue of `throw`.\r\nSince promises as we know them today bridged the migration gap from ECMAScript 3\r\nto ECMAScript 6, it was also necessary to use non-keywords for method names.\r\n\r\nA deferred value can be deferred further by resolving it with another promise.\r\nThis can occur either expressly through the resolver, or implicitly by returning\r\na promise as the result of a observer function.\r\n\r\n```js\r\nvar authenticated = getUsernameFromConsole()\r\n.then(function (username) {\r\n    return Promise.all([\r\n       getUserFromDatabase(username),\r\n       getPasswordFromConsole()\r\n    ])\r\n    .then(function ([user, password]) {\r\n        if (hash(password) !== user.passwordHash) {\r\n            throw new Error(\"Can't authenticate because the password is invalid\");\r\n        }\r\n    })\r\n})\r\n```\r\n\r\nThe `then` method internally creates a new deferred, returns the promise, and\r\nlater forwards the return value of the observer to the resolver.\r\nThis is a sketch of a `then` method that illustrates this adapter.\r\nNote that we create a deferred, use the resolver, and return the promise.\r\nThe adapter is responsible for catching errors and giving the consumer an\r\nopportunity to do further work or to recover.\r\n\r\n```js\r\nPromise.prototype.then = function Promise_then(onreturn, onthrow) {\r\n    var self = this;\r\n    var deferred = Promise.defer();\r\n    var resolver = deferred.resolver;\r\n    this.done(function (value) {\r\n        if (onreturn) {\r\n            try {\r\n                resolver.return(onreturn(value));\r\n            } catch (error) {\r\n                resolver.throw(error);\r\n            }\r\n        } else {\r\n            resolver.return(value);\r\n        }\r\n    }, function (error) {\r\n        if (onthrow) {\r\n            try {\r\n                resolver.return(onthrow(value));\r\n            } catch (error) {\r\n                resolver.throw(error);\r\n            }\r\n        } else {\r\n            resolver.throw(error);\r\n        }\r\n    });\r\n    return deferred.promise;\r\n```\r\n\r\nThe standard `Promise` does not reveal `Promise.defer()`.\r\nInstead, it is hidden by `then` and by the `Promise` constructor, which elects\r\nto hide the deferred object and the resolver object, instead \"revealing\" the\r\n`resolve` and `reject` methods as free arguments to a setup function, furthering\r\nthe need to give these functions names that are not keywords.\r\n\r\n```js\r\nvar promise = new Promise(function (resolve, reject) {\r\n    // ...\r\n});\r\n```\r\n\r\nWith a promise, information flows only from the first call to a resolver method\r\nto all promise observers, whether they are registered before or after the\r\nresolution.\r\n\r\nWith a task, information flows from the first call to a resolver method to the\r\nfirst call to an observer method, regardless of their relative order, but one\r\nkind of information can flow upstream.\r\nThe observer may unsubscribe with an error.\r\nThis is conceptually similar to throwing an error back into a generator from an\r\niterator and warrants the same interface.\r\n\r\n```js\r\ntask.throw(new Error(\"Never mind\"));\r\n```\r\n\r\nThis interface foreshadows its plural analogue: streams.\r\n\r\n\r\n### Asynchronous Functions\r\n\r\nGenerator functions have existed in other languages, like Python, for quite some\r\ntime, so folks have made some clever uses of them.\r\nWe can combine promises and generator functions to emulate asynchronous\r\nfunctions.\r\nThe key insight is a single, concise method that decorates a generator, creating\r\nan internal \"promise trampoline\".\r\nAn asynchronous function returns a promise for the eventual return value, or the\r\neventual thrown error, of the generator function.\r\nHowever, the function may yield promises to wait for intermediate values on its\r\nway to completion.\r\nThe trampoline takes advantage of the ability of an iterator to send a value\r\nfrom `next` to `yield`.\r\n\r\n```js\r\nvar authenticated = Promise.async(function *() {\r\n    var username = yield getUsernameFromConsole();\r\n    var user = getUserFromDatabase(username);\r\n    var password = getPasswordFromConsole();\r\n    [user, password] = yield Promise.all([user, password]);\r\n    if (hash(password) !== user.passwordHash) {\r\n        throw new Error(\"Can't authenticate because the password is invalid\");\r\n    }\r\n})\r\n```\r\n\r\nMark Miller’s [implementation][Async] of the `async` decorator is succinct and\r\ninsightful.\r\nWe produce a wrapped function that will create a promise generator and proceed\r\nimmediately.\r\nEach requested iteration has three possible outcomes: yield, return, or throw.\r\nYield waits for the given promise and resumes the generator with the eventual\r\nvalue.\r\nReturn stops the trampoline and returns the value, all the way out to the\r\npromise returned by the async function.\r\nIf you yield a promise that eventually throws an error, the async function\r\nresumes the generator with that error, giving it a chance to recover.\r\n\r\n[Async]: http://wiki.ecmascript.org/doku.php?id=strawman:async_functions#reference_implementation\r\n\r\n```js\r\nPromise.async = function async(generate) {\r\n    return function () {\r\n        function resume(verb, argument) {\r\n            var result;\r\n            try {\r\n                result = generator[verb](argument);\r\n            } catch (exception) {\r\n                return Promise.throw(exception);\r\n            }\r\n            if (result.done) {\r\n                return result.value;\r\n            } else {\r\n                return Promise.return(result.value).then(donext, dothrow);\r\n            }\r\n        }\r\n        var generator = generate.apply(this, arguments);\r\n        var donext = resume.bind(this, \"next\");\r\n        var dothrow = resume.bind(this, \"throw\");\r\n        return donext();\r\n    };\r\n}\r\n```\r\n\r\nAs much as JavaScript legitimizes the async promise generators by supporting\r\nreturning and throwing, now that Promises are part of the standard, the powers\r\nthat sit on the ECMAScript standards committee are contemplating special `async`\r\nand `await` syntax for this case.\r\nThe syntax is inspired by the same feature of C#.\r\n\r\n```js\r\nvar authenticate = async function () {\r\n    var username = await getUsernameFromConsole();\r\n    var user = getUserFromDatabase(username);\r\n    var password = getPasswordFromConsole();\r\n    [user, password] = await Promise.all([user, password]);\r\n    return hash(password) === user.passwordHash;\r\n})\r\n```\r\n\r\nOne compelling reason to support special syntax is that `await` may have higher\r\nprecedence than the `yield` keyword.\r\n\r\n```js\r\nasync function addPromises(a, b) {\r\n    return await a + await b;\r\n}\r\n```\r\n\r\nBy decoupling **async functions** from **generator functions**, JavaScript opens\r\nthe door for **async generator functions**, foreshadowing a **plural** and\r\n**temporal** getter, a standard form for readable streams.\r\n\r\n\r\n### Promise Queues\r\n\r\nConsider an asynchronous queue.\r\nWith a conventional queue, you must put a value in before you can take it out.\r\nThat is not the case for a promise queue.\r\nJust as you can attach an observer to a promise before it is resolved, with a\r\npromise queue, you can get a promise for the next value in order before that\r\nvalue has been given.\r\n\r\n```js\r\nvar queue = new Queue();\r\nqueue.get().then(function (value) {\r\n    console.log(value);\r\n})\r\nqueue.put(\"Hello, World!\");\r\n```\r\n\r\nLikewise of course you can add a value to the queue before observing it.\r\n\r\n```js\r\nvar queue = new Queue();\r\nqueue.put(\"Hello, World!\");\r\nqueue.get().then(function (value) {\r\n    console.log(value);\r\n})\r\n```\r\n\r\nAlthough promises come out of the queue in the same order their corresponding\r\nresolutions enter, a promise obtained later may settle sooner than another\r\npromise.\r\nThe values you put in the queue may themselves be promises.\r\n\r\n```js\r\nvar queue = new Queue();\r\nqueue.get().then(function () {\r\n    console.log(\"Resolves later\");\r\n});\r\nqueue.get().then(function () {\r\n    console.log(\"Resolves sooner\");\r\n});\r\nqueue.put(Promise.delay(100));\r\nqueue.put();\r\n```\r\n\r\nA promise queue qualifies as an asynchronous collection, specifically a\r\ncollection of results: values or thrown errors captured by promises.\r\nThe queue is not particular about what those values mean and is a suitable\r\nprimitive for many more interesting tools.\r\n\r\nInterface     |         |        |          |\r\n------------- | ------- | ------ | -------- |\r\nPromiseQueue  | Value   | Plural | Temporal |\r\nqueue.get     | Getter  | Plural | Temporal |\r\nqueue.put     | Setter  | Plural | Temporal |\r\n\r\nThe implementation of a promise queue is sufficiently succinct that there’s no\r\nharm in embedding it here.\r\nThis comes from Mark Miller's [Concurrency Strawman][] for ECMAScript and is a\r\npart of the Q library, exported by the `q/queue` module.\r\nInternally, a promise queue is an asynchronous linked list that tracks the\r\n`head` promise and `tail` deferred.\r\n`get` advances the `head` promise and `put` advances the `tail` deferred.\r\n\r\n```js\r\nmodule.exports = PromiseQueue;\r\nfunction PromiseQueue() {\r\n    if (!(this instanceof PromiseQueue)) {\r\n        return new PromiseQueue();\r\n    }\r\n    var ends = Promise.defer();\r\n    this.put = function (value) {\r\n        var next = Promise.defer();\r\n        ends.resolve({\r\n            head: value,\r\n            tail: next.promise\r\n        });\r\n        ends.resolve = next.resolve;\r\n    };\r\n    this.get = function () {\r\n        var result = ends.promise.get(\"head\");\r\n        ends.promise = ends.promise.get(\"tail\");\r\n        return result;\r\n    };\r\n}\r\n```\r\n\r\n[Concurrency Strawman]: http://wiki.ecmascript.org/doku.php?id=strawman:concurrency\r\n\r\nThe implementation uses methods defined in a closure.\r\nRegardless of how this is accomplished, it is important that it be possible to\r\npass the free `get` function to a consumer and `put` to a producer to preserve\r\nthe principle of least authority and the unidirectional flow of data from\r\nproducer to consumer.\r\n\r\nSee the accompanying sketch of a [promise queue][] implementation.\r\n\r\n[promise queue]: http://kriskowal.github.io/gtor/docs/promise-queue\r\n\r\nA promise queue does not have a notion of termination, graceful or otherwise.\r\nWe will later use a pair of promise queues to transport iterations between\r\n**streams**.\r\n\r\n\r\n### Semaphores\r\n\r\nSemaphores are flags or signs used for communication and were precursors to\r\ntelegraphs and traffic lights.\r\nIn programming, semaphores are usually used to synchronize programs that share\r\nresources, where only one process can use a resource at one time.\r\nFor example, if a process has a pool of four database connections, it would use\r\na semaphore to manage that pool.\r\n\r\nTypically, semaphores are used to block a thread or process from continuing\r\nuntil a resource becomes available.\r\nThe process will \"down\" the semaphore whenever it enters a region where it needs\r\na resource, and will \"up\" the semaphore whenever it exits that region.\r\nThe terminology goes back to raising and lowering flags.\r\nYou can imagine your process as being a train and a semaphore as guarding the\r\nentrance to a particular length of track.\r\nYour process stops at the gate until the semaphore goes up.\r\n\r\nOf course, in a reactive program, we don’t block.\r\nInstead of blocking, we return promises and continue when a promise resolves.\r\nWe can use a promise as a non-blocking mutex for a single resource, and a\r\npromise queue as a non-blocking semaphore for multiple resources.\r\n\r\nIn this example, we establish three database connections that are shared by a\r\nfunction that can be called to do some work with the first available connection.\r\nWe get the resource, do our work, and regardless of whether we succeed or fail,\r\nwe put the resource back in the pool.\r\n\r\n```js\r\nvar connections = new Queue();\r\nconnections.put(connectToDb());\r\nconnections.put(connectToDb());\r\nconnections.put(connectToDb());\r\n\r\nfunction work() {\r\n    return connections.get()\r\n    .then(function (db) {\r\n        return workWithDb(db)\r\n        .finally(function () {\r\n            connections.put(db);\r\n        })\r\n    });\r\n}\r\n```\r\n\r\n\r\n### Promise Buffers\r\n\r\nConsider another application.\r\nYou have a producer and a consumer, both doing work asynchronously, the producer\r\nperiodically sending a value to the consumer.\r\nTo ensure that the producer does not produce faster than the consumer can\r\nconsume, we put an object between them that regulates their flow rate: a buffer.\r\nThe buffer uses a promise queue to transport values from the producer to the\r\nconsumer, and another promise queue to communicate that the consumer is ready\r\nfor another value from the producer.\r\nThe following is a sketch to that effect.\r\n\r\n```js\r\nvar outbound = new PromiseQueue();\r\nvar inbound = new PromiseQueue();\r\nvar buffer = {\r\n    out: {\r\n        next: function (value) {\r\n            outbound.put({\r\n                value: value,\r\n                done: false\r\n            });\r\n            return inbound.get();\r\n        },\r\n        return: function (value) {\r\n            outbound.put({\r\n                value: value,\r\n                done: true\r\n            })\r\n            return inbound.get();\r\n        },\r\n        throw: function (error) {\r\n            outbound.put(Promise.throw(error));\r\n            return inbound.get();\r\n        }\r\n    },\r\n    in: {\r\n        yield: function (value) {\r\n            inbound.put({\r\n                value: value,\r\n                done: false\r\n            })\r\n            return outbound.get();\r\n        },\r\n        return: function (value) {\r\n            inbound.put({\r\n                value: value,\r\n                done: true\r\n            })\r\n            return outbound.get();\r\n        },\r\n        throw: function (error) {\r\n            inbound.put(Promise.throw(error));\r\n            return outbound.get();\r\n        }\r\n    }\r\n};\r\n```\r\n\r\nThis sketch uses the vernacular of iterators and generators, but each of these\r\nhas equivalent nomenclature in the world of streams.\r\n\r\n-   `in.yield` means “write”.\r\n-   `in.return` means “close”.\r\n-   `in.throw` means “terminate prematurely with an error”.\r\n-   `out.next` means “read”.\r\n-   `out.throw` means “abort or cancel with an error”.\r\n-   `out.return` means “abort or cancel prematurely but without an error”.\r\n\r\nSo a buffer fits in the realm of reactive interfaces.\r\nA buffer has an asynchronous iterator, which serves as the getter side.\r\nIt also has an asynchronous generator, which serves as the setter dual.\r\nThe buffer itself is akin to an asynchronous, plural value.\r\nIn addition to satisfying the requirements needed just to satisfy the\r\ntriangulation between synchronous iterables and asynchronous promises,\r\nit solves the very real world need for streams that support pressure\r\nto regulate the rate of flow and avoid over-commitment.\r\nAn asynchronous iterator is a readable stream.\r\nAn asynchronous generator is a writable stream.\r\n\r\nStream            |         |          |              |\r\n----------------- | ------- | -------- | ------------ |\r\nPromise Buffer    | Value   | Plural   | Temporal     |\r\nPromise Iterator  | Getter  | Plural   | Temporal     |\r\nPromise Generator | Setter  | Plural   | Temporal     |\r\n\r\nA buffer has a reader and writer, but there are implementations of reader and\r\nwriter that interface with the outside world, mostly files and sockets.\r\n\r\nIn the particular case of an object stream, if we treat `yield` and `next` as\r\nsynonyms, the input and output implementations are perfectly symmetric.\r\nThis allows a single constructor to serve as both reader and writer.\r\nAlso, standard promises use the [Revealing Constructor] pattern, exposing the\r\nconstructor for the getter side.\r\nThe standard hides the `Promise.defer()` constructor method behind the scenes,\r\nonly exposing the `resolver` as arguments to a setup function, and never\r\nrevealing the `{promise, resolver}` deferred object at all.\r\nSimilarly, we can hide the promise buffer constructor and reveal the input side\r\nof a stream only as arguments to the output stream constructor.\r\n\r\n```js\r\nvar reader = new Stream(function (write, close, abort) {\r\n    // ...\r\n});\r\n```\r\n\r\nThe analogous method to `Promise.defer()` might be `Stream.buffer()`, which\r\nwould return an `{in, out}` pair of entangled streams.\r\n\r\n[Revealing Constructor]: http://domenic.me/2014/02/13/the-revealing-constructor-pattern/\r\n\r\nSee the accompanying sketch of a [stream][] implementation.\r\n\r\n[stream]: http://kriskowal.github.io/gtor/docs/stream\r\n\r\n\r\n### Promise Iterators\r\n\r\nOne very important kind of promise iterator lifts a spatial iterator into the\r\ntemporal dimension so it can be consumed on demand over time.\r\nIn this sketch, we just convert a synchronous `next` method to a method that\r\nreturns a promise for the next iteration instead.\r\nWe use a mythical `iterate` function which would create iterators for all\r\nsensible JavaScript objects and delegate to the `iterate` method of anything\r\nelse that implements it.\r\nThere is talk of using symbols in ES7 to avoid recognizing accidental iterables\r\nas this new type of duck.\r\n\r\n```js\r\nfunction PromiseIterator(iterable) {\r\n    this.iterator = iterate(iterable);\r\n}\r\nPromiseIterator.prototype.next = function () {\r\n    return Promise.return(this.iterator.next());\r\n};\r\n```\r\n\r\nThe conversion may seem superfluous at first.\r\nHowever, consider that a synchronous iterator might, apart from implementing\r\n`next()`, also implement methods analogous to `Array`, like `forEach`,\r\n`map`, `filter`, and `reduce`.\r\nLikewise, an asynchronous iterator might provide analogues to these functions\r\nlifted into the asynchronous realm.\r\n\r\nThe accompanying sketch of a stream constructor implements a method\r\n`Stream.from`, analogous to ECMAScript 6's own `Array.from`.\r\nThis function coerces any iterable into a stream, consuming that iterator on\r\ndemand.\r\nThis allows us, for example, to run an indefinite sequence of jobs, counting\r\nfrom 1, doing four jobs at any time.\r\n\r\n```js\r\nStream.from(Iterator.range(1, Infinity))\r\n.forEach(function (n) {\r\n    return Promise.delay(1000).thenReturn(n);\r\n}, null, 4)\r\n.done();\r\n```\r\n\r\n#### map\r\n\r\nFor example, asynchronous `map` would consume iterations and run jobs on each of\r\nthose iterations using the callback.\r\nHowever, unlike a synchronous `map`, the callback might return a promise for\r\nits eventual result.\r\nThe results of each job would be pushed to an output reader, resulting in\r\nanother promise that the result has been consumed.\r\nThis promise not only serves to produce the corresponding output iteration, but\r\nalso serves as a signal that the job has completed, that the output has been\r\nconsumed, and that the `map` can schedule additional work.\r\nAn asynchronous `map` would accept an additional argument that would limit the\r\nnumber of concurrent jobs.\r\n\r\n```js\r\npromiseIterator.map(function (value) {\r\n    return Promise.return(value + 1000).delay(1000);\r\n});\r\n```\r\n\r\n#### forEach\r\n\r\nSynchronous `forEach` does not produce an output collection or iterator.\r\nHowever, it does return `undefined` *when it is done*.\r\nOf course synchronous functions are implicitly completed when they return,\r\nbut asynchronous functions are done when the asynchronous value they return\r\nsettles.\r\n`forEach` returns a promise for `undefined`.\r\n\r\nSince streams are **unicast**, asynchronous `forEach` would return a task.\r\nIt stands to reason that the asynchronous result of `forEach` on a stream would\r\nbe able to propagate a cancellation upstream, stopping the flow of data from the\r\nproducer side.\r\nOf course, the task can be easily forked or coerced into a promise if it needs\r\nto be shared freely among multiple consumers.\r\n\r\n```js\r\nvar task = reader.forEach(function (n) {\r\n    console.log(\"consumed\", n);\r\n    return Promise.delay(1000).then(function () {\r\n        console.log(\"produced\", n);\r\n    });\r\n})\r\nvar subtask = task.fork();\r\nvar promise = Promise.return(task);\r\n```\r\n\r\nLike `map` it would execute a job for each iteration, but by default it would\r\nperform these jobs in serial.\r\nAsynchronous `forEach` would also accept an additional argument that would\r\n*expand* the number of concurrent jobs.\r\nIn this example, we would reach out to the database for 10 user records at any\r\ngiven time.\r\n\r\n```js\r\nreader.forEach(function (username) {\r\n    return database.getUser(username)\r\n    .then(function (user) {\r\n        console.log(user.lastModified);\r\n    })\r\n}, null, 10);\r\n```\r\n\r\n#### reduce\r\n\r\nAsynchronous `reduce` would aggregate values from the input reader, returning a\r\npromise for the composite value.\r\nThe reducer would have an internal pool of aggregated values.\r\nWhen the input is exhausted and only one value remains in that pool, the reducer\r\nwould resolve the result promise.\r\nIf you provide a basis value as an argument, this would be used to \"prime the\r\npump\".\r\nThe reducer would then start some number of concurrent aggregator jobs, each\r\nconsuming two values.\r\nThe first value would preferably come from the pool, but if the pool is empty,\r\nwould come from the input.\r\nThe second value would come unconditionally from the input.\r\nWhenever a job completes, the result would be placed back in the pool.\r\n\r\n#### pipe\r\n\r\nAn asynchronous iterator would have additional methods like `copy` or `pipe`\r\nthat would send iterations from this reader to another writer.\r\nThis method would be equivalent to using `forEach` to forward iterations and\r\n`then` to terminate the sequence.\r\n\r\n```js\r\niterator.copy(generator);\r\n// is equivalent to:\r\niterator.forEach(generator.yield).then(generator.return, generator.throw);\r\n```\r\n\r\nNote that the promise returned by yield applies pressure on the `forEach`\r\nmachine, pushing ultimately back on the iterator.\r\n\r\n#### buffer\r\n\r\nIt would have `buffer` which would construct a buffer with some capacity.\r\nThe buffer would try to always have a value on hand for its consumer by\r\nprefetching values from its producer.\r\nIf the producer is faster than the consumer, this can help avoid round trip\r\nlatency when the consumer needs a value from the producer.\r\n\r\n#### read\r\n\r\nJust as it is useful to transform a synchronous collection into an iterator and\r\nan iterator into a reader, it is also useful to go the other way.\r\nAn asynchronous iterator would also have methods that would return a promise for\r\na collection of all the values from the source, for example `all`, or in the\r\ncase of readers that iterate collections of bytes or characters, `join` or\r\n`read`.\r\n\r\n\r\n#### Remote iterators\r\n\r\nConsider also that a reader may be a proxy for a remote reader.\r\nA promise iterator be easily backed by a promise for a remote object.\r\n\r\n```js\r\nfunction RemotePromiseIterator(promise) {\r\n    this.remoteIteratorPromise = promise.invoke(\"iterate\");\r\n}\r\nRemotePromiseIterator.prototype.next = function (value) {\r\n    return this.remoteIteratorPromise.invoke(\"next\");\r\n};\r\n\r\nvar remoteReader = remoteFilesystem.invoke(\"open\", \"primes.txt\");\r\nvar reader = new RemotePromiseIterator(remoteReader);\r\nreader.forEach(console.log);\r\n```\r\n\r\nApart from `then` and `done`, promises provide methods like `get`, `call`, and\r\n`invoke` to allow promises to be created from promises and for messages to be\r\npipelined to remote objects.\r\nAn `iterate` method should be a part of that protocol to allow values to be\r\nstreamed on demand over any message channel.\r\n\r\n\r\n### Promise Generators\r\n\r\nA promise generator is analogous in all ways to a plain generator.\r\nPromise generators implement `yield`, `return`, and `throw`.\r\nThe return and throw methods both terminate the stream.\r\nYield accepts a value.\r\nThey all return promises for an acknowledgement iteration from the consumer.\r\nWaiting for this promise to settle causes the producer to idle long enough for\r\nthe consumer to process the data.\r\n\r\nOne can increase the number of promises that can be held in flight by a promise\r\nbuffer.\r\nThe buffer constructor takes a `length` argument that primes the acknowledgement\r\nqueue, allowing you to send that number of values before having to wait for the\r\nconsumer to flush.\r\n\r\n```js\r\nvar buffer = new Buffer(1024);\r\nfunction fibStream(a, b) {\r\n    return buffer.in.yield(a)\r\n    .then(function () {\r\n        return fibStream(b, a + b);\r\n    });\r\n}\r\nfibStream(1, 1).done();\r\nreturn buffer.out;\r\n```\r\n\r\nIf the consumer would like to terminate the producer prematurely, it calls the\r\n`throw` method on the corresponding promise iterator.\r\nThis will eventually propagate back to the promise returned by the generator’s\r\n`yield`, `return`, or `throw`.\r\n\r\n```js\r\nbuffer.out.throw(new Error(\"That's enough, thanks\"));\r\n```\r\n\r\n\r\n### Asynchronous Generator Functions\r\n\r\nJafar Husain recently [asked the ECMAScript committee][JH1], whether generator\r\nfunctions and async functions were composable, and if so, how they should\r\ncompose. (His [proposal][JH2] continues to evolve.)\r\n\r\n[JH1]: https://docs.google.com/file/d/0B7zweKma2uL1bDBpcXV4OWd2cnc\r\n[JH2]: https://github.com/jhusain/asyncgenerator\r\n\r\nOne key question is what type an async generator function would return.\r\nWe look to precedent.\r\nA generator function returns an iterator.\r\nA asynchronous function returns a promise.\r\nShould the asynchronous generator return a promise for an iterator, an iterator\r\nfor promises?\r\n\r\nIf ``Iterator<T>`` means that an iterator implements `next` such that it\r\nproduces ``Iteration<T>``, the `next` method of an ``Iterator<Promise<T>>``\r\nwould return an ``Iteration<Promise<T>>``, which is to say, iterations that\r\ncarry promises for values.\r\n\r\nThere is another possibility.\r\nAn asynchronous iterator might implement `next` such that it produces\r\n``Promise<Iteration<T>>`` rather than ``Iteration<Promise<T>>``.\r\nThat is to say, a promise that would eventually produce an iteration containing\r\na value, rather than an iteration that contains a promise for a value.\r\n\r\nThis is, an iterator of promises, yielding ``Iteration<Promise<T>>``:\r\n\r\n```js\r\nvar iteration = iterator.next();\r\niteration.value.then(function (value) {\r\n    return callback.call(thisp, value);\r\n});\r\n```\r\n\r\nThis is a promise iterator, yielding ``Promise<Iteration<T>>``:\r\n\r\n```js\r\npromiseIterator.next()\r\n.then(function (iteration) {\r\n    return callback.call(thisp, iteration.value);\r\n})\r\n```\r\n\r\nPromises capture asynchronous results.\r\nThat is, they capture both the value and error cases.\r\nIf `next` returns a promise, the error case would model abnormal termination of\r\na sequence.\r\nIterations capture the normal continuation or termination of a sequence.\r\nIf the value of an iteration were a promise, the error case would capture\r\ninability to transport a single value but would not imply termination of the\r\nsequence.\r\n\r\nIn the context of this framework, the answer is clear.\r\nAn asynchronous generator function uses both `await` and `yield`.\r\nThe `await` term allows the function to idle until some asynchronous work has\r\nsettled, and the `yield` allows the function to produce a value.\r\nAn asynchronous generator returns a promise iterator, the output side of a\r\nstream.\r\n\r\nRecall that an iterator returns an iteration, but a promise iterator returns a\r\npromise for an iteration, and also a promise generator returns a similar promise\r\nfor the acknowledgement from the iterator.\r\n\r\n```js\r\npromiseIterator.next()\r\n.then(function (iteration) {\r\n    console.log(iteration.value);\r\n    if (iteration.done) {\r\n        console.log(\"fin\");\r\n    }\r\n});\r\n\r\npromiseGenerator.yield(\"alpha\")\r\n.then(function (iteration) {\r\n    console.log(\"iterator has consumed alpha\");\r\n});\r\n```\r\n\r\nThe following example will fetch quotes from the works of Shakespeare, retrieve\r\nquotes from each work, and push those quotes out to the consumer.\r\nNote that the `yield` expression returns a promise for the value to flush, so\r\nawaiting on that promise allows the generator to pause until the consumer\r\ncatches up.\r\n\r\n```js\r\nasync function *shakespeare(titles) {\r\n    for (let title of titles) {\r\n        var quotes = await getQuotes(title);\r\n        for (let quote of quotes) {\r\n            await yield quote;\r\n        }\r\n    }\r\n}\r\n\r\nvar reader = shakespeare([\"Hamlet\", \"Macbeth\", \"Othello\"]);\r\nreader.reduce(function (length, quote) {\r\n    return length + quote.length;\r\n}, 0, null, 100)\r\n.then(function (totalLength) {\r\n    console.log(totalLength);\r\n});\r\n```\r\n\r\nIt is useful for `await` and `yield` to be completely orthogonal because there\r\nare cases where one will want to yield but ignore pressure from the consumer,\r\nforcing the iteration to buffer.\r\n\r\nJafar also proposes the existence of an `on` operator.\r\nIn the context of this framework, the `on` operator would be similar to the\r\nECMAScript 6 `of` operator, which accepts an iterable, produces an iterator, and\r\nthen walks the iterator.\r\n\r\n```js\r\nfor (let a of [1, 2, 3]) {\r\n    console.log(a);\r\n}\r\n\r\n// is equivalent to:\r\n\r\nvar anIterable = [1, 2, 3];\r\nvar anIterator = anIterable[Symbol.iterate]();\r\nwhile (true) {\r\n    let anIteration = anIterator.next();\r\n    if (anIteration.done) {\r\n        break;\r\n    } else {\r\n        var aValue = anIteration.value;\r\n        console.log(aValue);\r\n    }\r\n}\r\n```\r\n\r\nThe `on` operator would operate on an asynchronous iterable, producing an\r\nasynchronous iterator, and await each promised iteration.\r\nLook for the `await` in the following example.\r\n\r\n```js\r\nfor (let a on anAsyncIterable) {\r\n    console.log(a);\r\n}\r\n\r\n// is equivalent to:\r\n\r\nvar anAsyncIterator = anAsyncIterable[Symbol.iterate]();\r\nwhile (true) {\r\n    var anAsyncIteration = anAsyncIterator.next();\r\n    var anIteration = await anAsyncIteration;\r\n    if (anIteration.done) {\r\n        break;\r\n    } else {\r\n        var aValue = anIteration.value;\r\n        console.log(aValue);\r\n    }\r\n}\r\n```\r\n\r\nOne point of interest is that the `on` operator would work for both asynchronous\r\nand synchronous iterators and iterables, since `await` accepts both values and\r\npromises.\r\n\r\nJafar proposes that the asynchronous analogues of `iterate()` would be\r\n`observe(generator)`, from which it is trivial to derrive `forEach`, but I\r\npropose that the asynchronous analogues of `iterate()` would just be\r\n`iterate()` and differ only in the type of the returned iterator.\r\nWhat Jafar proposes as the `asyncIterator.observe(asyncGenerator)` method is\r\neffectively equivalent to synchronous `iterator.copy(generator)` or\r\n`stream.pipe(stream)`.\r\nIn this framework, `copy` would be implemented in terms of `forEach`.\r\n\r\n```js\r\nStream.prototype.copy = function (stream) {\r\n    return this.forEach(stream.next).then(stream.return, stream.throw);\r\n};\r\n```\r\n\r\nAnd, `forEach` would be implemented in terms of `next`, just as it would be\r\nlayered on a synchronous iterator.\r\n\r\n\r\n### Observables\r\n\r\nThere is more than one way to solve the problem of processor contention or\r\nprocess over-scheduling.\r\nStreams have a very specific contract that makes pressurization necessary.\r\nSpecifically, a stream is intended to transport the entirety of a collection and\r\nstrongly resembles a spatial collection that has been rotated 90 degrees onto\r\nthe temporal axis.\r\nHowever, there are other contracts that lead us to very different strategies to\r\navoid over-commitment and they depend entirely on the meaning of the data in\r\ntransit.\r\nThe appropriate transport is domain specific.\r\n\r\nConsider a sensor, like a thermometer or thermocouple.\r\nAt any given time, the subject will have a particular temperature.\r\nThe temperature may change continuously in response to events that are not\r\nsystematically observable.\r\nSuppose that you poll the thermocouple at one second intervals and place that on\r\nsome plural, asynchronous setter.\r\nSuppose that this ultimately gets consumed by a visualization that polls the\r\ncorresponding plural, asynchronous getter sixty times per second.\r\nThe visualization is only interested in the most recently sampled value from the\r\nsensor.\r\n\r\nConsider a variable like the position of a scrollbar.\r\nThe value is discrete.\r\nIt does not change continuously.\r\nRather, it changes only in response to an observable event.\r\nEach time one of these scroll events occurs, we place the position on the\r\nsetter side of some temporal collection.\r\nAny number of consumers can subscribe to the getter side and it will push a\r\nnotification their way.\r\n\r\nHowever, if we infer a smooth animation from the discrete scroll positions and\r\ntheir times, we can sample the scroll position *function* on each animation\r\nframe.\r\n\r\nThese cases are distinct from streams and have interesting relationships with\r\neach other.\r\nWith the temperature sensor, changes are **continuous**, whereas with the scroll\r\nposition observer, the changes are **discrete**.\r\nWith the temperature sensor, we sample the data at a much lower frequency than\r\nthe display, in which case it is sufficient to remember the last sensed\r\ntemperature and redisplay it.\r\nIf we were to sample the data at a higher frequency than the display, it would\r\nbe sufficient for the transport to forget old values each time it receives a new\r\none.\r\nAlso, unlike a stream, these cases are both well adapted for multiple-producer\r\nand multiple-consumer scenarios.\r\n\r\nAlso unlike streams, one of these concepts pushes data and the other polls or\r\npulls data.\r\nA stream has pressure, which is a kind of combined pushing and pulling.\r\nData is pulled toward the consumer by a vacuum.\r\nProducers are pushed back by pressure when the vacuum is filled, thus the term:\r\nback-pressure.\r\n\r\nThe discrete event pusher is a Signal.\r\nThe continuous, pollable is a Behavior.\r\n\r\n\r\nInterface          |               |      |\r\n------------------ | --------------| ---- |\r\nSignal Observable  | Get           | Push |\r\nSignal Generator   | Set           | Push |\r\nSignal             | Value         | Push |\r\nBehavior Iterator  | Get           | Poll |\r\nBehavior Generator | Set           | Poll |\r\nBehavior           | Value         | Poll |\r\n\r\n\r\n-   TODO make sure this is a summary of the topics in the end:\r\n\r\nYet even behaviors have variations like probes, gauges, counters,\r\nflow gauges, accumulators, flushable accumulators, and rotating counters.\r\n\r\n\r\n### Observables and Signals\r\n\r\nA **signal** represents a value that changes over time.\r\nThe signal is asynchronous and plural, like a stream.\r\nUnlike a stream, a signal can have multiple producers and consumers.\r\nThe output side of a signal is an **observable**.\r\n\r\nA signal has a getter side and a setter side.\r\nThe asynchronous getter for a signal is an observable instead of a reader.\r\nThe observable implements `forEach`, which subscribes an observer to receive\r\npush notifications whenever the signal value changes.\r\n\r\n```js\r\nsignal.out.forEach(function (value, time, signal) {\r\n    console.log(value);\r\n})\r\n```\r\n\r\nThe signal generator is the asynchronous setter.\r\nLike a stream writer, it implements `yield`.\r\nHowever, unlike a stream writer, `yield` does not return a promise.\r\n\r\n```js\r\nsignal.in.yield(10);\r\n```\r\n\r\nSignals do not support pressure.\r\nJust as `yield` does not return a promise, the callback you give to `forEach`\r\ndoes not accept a promise.\r\nA signal can only push.\r\nThe consumer (or consumers) cannot push back.\r\n\r\nObservables *also* implement `next`, which returns an iteration that captures\r\nthe most recently dispatched value.\r\nThis allows us to poll a signal as if it were a behavior.\r\n\r\nSee the accompanying sketch of a [observable][] implementation.\r\n\r\n[observable]: http://kriskowal.github.io/gtor/docs/observable\r\n\r\nJust as streams relate to buffers, not every observable must be paired with a\r\nsignal generator.\r\nA noteworthy example of an external observable is a clock.\r\nA clock emits a signal with the current time at a regular period and offset.\r\n\r\n```js\r\nvar tick = new Clock({period: 1000});\r\nvar tock = new Clock({period: 1000, offset: 500});\r\ntick.forEach(function (time) {\r\n    console.log(\"tick\", time);\r\n})\r\ntock.forEach(function (time) {\r\n    console.log(\"tock\", time);\r\n});\r\n```\r\n\r\nSee the accompanying sketch of a [clock][] implementation.\r\n\r\n[clock]: http://kriskowal.github.io/gtor/docs/clock\r\n\r\nSignals may correspond to system or platform signals like keyboard or mouse\r\ninput or other external sensors.\r\nFurthermore, a signal generator might dispatch a system level signal to another\r\nprocess, for example SIGHUP, which typically asks a daemon to reload its\r\nconfiguration.\r\n\r\n```js\r\ndaemon.signals.yield(\"SIGHUP\");\r\n```\r\n\r\n\r\n### Behaviors\r\n\r\nA behavior represents a time series value.\r\nA behavior may produce a different value for every moment in time.\r\nAs such, they must be **polled** at an interval meaningful to the consumer,\r\nsince the behavior itself has no inherent resolution.\r\n\r\nBehaviors are analogous to Observables, but there is no corresponding setter,\r\nsince it produces values on demand.\r\nThe behavior constructor accepts a function that returns the value for a given\r\ntime.\r\nAn asynchronous behavior returns promises instead of values.\r\n\r\nSee the accompanying sketch of a [behavior][] implementation.\r\n\r\n[behavior]: http://kriskowal.github.io/gtor/docs/behavior\r\n\r\n\r\n## Cases\r\n\r\n### Progress and estimated time to completion\r\n\r\nImagine you are copying the values from a stream into an array.\r\nYou know how long the array will be and when you started reading.\r\nKnowing these variables and assuming that the rate of flow is steady, you can\r\ninfer the amount of **progress** that has been made up to the current time.\r\nThis is a simple matter of dividing the number of values you have so far\r\nreceived, by the total number of values you expect to receive.\r\n\r\n```js\r\nvar progress = index / length;\r\n```\r\n\r\nThis is a discrete measurement that you can push each time you receive another\r\nvalue.\r\nIt is discrete because it does not change between events.\r\n\r\nYou can also infer the average **throughput** of the stream, also a discrete\r\ntime series.\r\n\r\n```js\r\nvar elapsed = now - start;\r\nvar throughput = index / elapsed;\r\n```\r\n\r\nFrom progress you can divine an **estimated time of completion**.\r\nThis will be the time you started plus the time you expect the whole stream to\r\ntake.\r\n\r\n```js\r\nvar stop = start + elapsed / progress;\r\nvar stop = start + elapsed / (index / length);\r\nvar stop = start + elapsed * length / index;\r\n```\r\n\r\nWe could update a progress bar whenever we receive a new value, but frequently\r\nwe would want to display a smooth animation continuously changing.\r\nIdeally, progress would proceed linearly from 0 at the start time to 1 at the\r\nstop time.\r\nYou could sample progress at any moment in time and receive a different value.\r\nValues that lack an inherent resolution are *continuous*.\r\nIt becomes the responsibility of the consumer to determine when to sample,\r\n**pull** or **poll** the value.\r\n\r\nFor the purposes of a smooth animation of a continuous behavior, the frame rate\r\nis a sensible polling frequency.\r\nWe can infer a continuous progress time series from the last known estimated time\r\nof completion.\r\n\r\n```js\r\nvar progress = (now - start) / (estimate - start);\r\n```\r\n\r\n\r\n## Summary\r\n\r\nReactive primitives can be categorized in multiple dimensions.\r\nThe interfaces of analogous non-reactive constructs including getters, setters,\r\nand generators are insightful in the design of their asynchronous counterparts.\r\nIdentifying whether a primitive is singular or plural also greatly informs the\r\ndesign.\r\n\r\nWe can use pressure to deal with resource contention while guaranteeing\r\nconsistency.\r\nWe can alternately use push or poll strategies to skip irrelevant states for\r\neither continuous or discrete time series data with behaviors or signals.\r\n\r\nThere is a tension between cancelability and robustness, but we have primitives\r\nthat are useful for both cases.\r\nStreams and tasks are inherently cooperative, cancelable, and allow\r\nbidirectional information flow.\r\nPromises guarantee that consumers and producers cannot interfere.\r\n\r\nAll of these concepts are related and their implementations benefit from mutual\r\navailability.\r\nPromises and tasks are great for single result data, but can provide a\r\nconvenient channel for plural signals and behaviors.\r\n\r\nBringing all of these reactive concepts into a single framework gives us an\r\nopportunity to tell a coherent story about reactive programming, promotes a\r\nbetter understanding about what tool is right for the job, and obviates the\r\ndebate over whether any single primitive is a silver bullet.\r\n\r\n\r\n## Further Work\r\n\r\nThere are many more topics that warrant discussion and I will expand upon these\r\nhere.\r\n\r\nReservoir sampling can be modeled as a behavior that watches a stream or signal\r\nand produces a representative sample on demand.\r\n\r\nA clock user interface is a good study in the interplay between behaviors,\r\nsignals, time, and animation scheduling.\r\n\r\nDrawing from my experience at FastSoft, we exposed variables from the kernel's\r\nnetworking stack so we could monitor the bandwidth running through our TCP\r\nacceleration appliance.\r\nSome of those variables modeled the number of packets transmitted and the number\r\nof bytes transmitted.\r\nThese counters would frequently overflow.\r\nThere are several interesting ways to architect a solution that would provide\r\nhistorical data in multiple resolutions, accounting for the variable overflow,\r\ninvolving a combination of streams, behaviors, and signals.\r\nI should draw your attention to design aspects of RRDTool.\r\n\r\nAn advantage of having a unified framework for reactive primitives is to create\r\nsimple stories for passing one kind of primitive to another.\r\nPromises can be coerced to tasks, tasks to promises.\r\nA signal can be used as a behavior, and a behavior can be captured by a signal.\r\nSignals can be channeled into streams, and streams can be channeled into\r\nsignals.\r\n\r\nIt is worth exploring in detail how operators can be lifted in each of these\r\nvalue spaces.\r\n\r\nImplementing distributed sort using streams is also a worthy exercise.\r\n\r\nAsynchronous behaviors would benefit from an operator that solves the thundering\r\nherd problem, the inverse of throttling.\r\n\r\nHow to implement type ahead suggestion is a great case to explore cancelable\r\nstreams and tasks.\r\n\r\nI also need to discuss how these reactive concepts can propagate operational\r\ntransforms through queries, using both push and pull styles, and how this\r\nrelates to bindings, both synchronous and asynchronous.\r\n\r\nI also need to compare and contrast publishers and subscribers to the related\r\nconcepts of signals and streams.\r\nIn short, publishers and subscribers are broadcast, unlike unicast streams,\r\nbut a single subscription could be modeled as a stream.\r\nHowever, a subscriber can typically not push back on a publisher, so how\r\nresource contention is alleviated is an open question.\r\n\r\nRelated to publishing and subscribing, streams can certainly be forked, in which\r\ncase both branches would put pressure back on the source.\r\n\r\nStreams also have methods that return tasks.\r\nAll of these could propagate estimated time to completion.\r\nEach of the cases for `all`, `any`, `race`, and `read` are worth exploring.\r\n\r\nHigh performance buffers for bytewise data with the promise buffer interface\r\nrequire further exploration.\r\n\r\nImplementing a retry loop with promises and tasks is illustrative.\r\n\r\nReactive Extensions (Rx) beg a distinction between [hot and cold][] observables,\r\nwhich is worth exploring.\r\nThe clock reference implementation shows one way to implement a signal that can\r\nbe active or inactive based on whether anyone is looking.\r\n\r\n[hot and cold]: https://github.com/Reactive-Extensions/RxJS/blob/master/doc/gettingstarted/creating.md#cold-vs-hot-observables\r\n\r\nThe research into continuous behaviors and the original idea of Functional\r\nReactive Programming by [Conal Elliott][] deserves attention.\r\n\r\n[Conal Elliott]: http://conal.net/\r\n\r\nThe interplay between promises and tasks with their underlying progress behavior\r\nand estimated time to completion and status signals require further explanation.\r\nThese ideas need to be incorporated into the sketches of promise and task\r\nimplementations.\r\n\r\n## Acknowledgements\r\n\r\nI am grateful to Domenic Denicola, Ryan Paul, and Kevin Smith for reviewing and\r\nproviding feedback on various drafts of this article.\r\n","desc":"No description."},{"title":"hw4","lastOpen":1559802231091,"TotalTime":593557979,"words":74,"path":"D:\\Projects\\XNote\\app\\saves\\hw4.md","content":"# DEMO\nThis is X-Note\n# Demo\nThis is X-Note\n$$\\sum_{k=1}^{\\infty} \\frac{1}{k^2}$$","desc":"No description."},{"title":"Review","lastOpen":1559802063021,"TotalTime":3978592209,"words":2284,"path":"D:\\Projects\\XNote\\app\\saves\\Review.md","content":"","desc":"No description."},{"title":"test","lastOpen":1558422742733,"TotalTime":42166,"words":56,"path":"D:\\Projects\\XNote\\app\\saves\\test.txt","content":"","desc":"No description."},{"title":"buffer","lastOpen":1558422635337,"TotalTime":72818,"words":2609,"path":"D:\\Projects\\XNote\\app\\saves\\buffer.md","content":"","desc":"No description."}]}